---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE, message = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#",
  fig.path = "tools/images/README-"
)
library(sparkts)
```

# sparkts

[![Project Status: Active - The project has reached a stable, usable state and is being actively developed.](http://www.repostatus.org/badges/latest/active.svg)](http://www.repostatus.org/#active)
[![CRAN_Status_Badge](http://www.r-pkg.org/badges/version/sparkts)](http://cran.r-project.org/package=sparkts)
[![Travis-CI Build Status](https://travis-ci.org/nathaneastwood/sparkts.svg?branch=master)](https://travis-ci.org/nathaneastwood/sparkts)
[![Coverage Status](https://img.shields.io/codecov/c/github/nathaneastwood/sparkts/master.svg)](https://codecov.io/github/nathaneastwood/sparkts?branch=master)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

The goal of `sparkts` is to provide a test bed of `sparklyr` extensions for the [`spark-ts`](https://github.com/srussell91/SparkTS) framework which was modified from the [`spark-timeseries`](https://github.com/sryza/spark-timeseries) framework.

## Installation

You can install `sparkts` from GitHub with:

```{r installation, eval = FALSE}
# install.packages("devtools")
devtools::install_github("nathaneastwood/sparkts")
```

## Example

This is a basic example which shows you how to calculate the standard error for some time series data:

```{r example, cache = TRUE}
# Set up a spark connection
sc <- sparklyr::spark_connect(master = "local", version = "2.1.0")

# Extract some data
std_data <- sparklyr::spark_read_json(
  sc,
  "std_data",
  path = system.file(
    "data_raw/StandardErrorDataIn.json",
    package = "sparkts"
  )
) %>%
  sparklyr::spark_dataframe()

# Instantiate the class
p <- sdf_standard_error$new(sc = sc, data = std_data)

# Calculate the standard errors
p$standard_error(
  x_col = "xColumn", y_col = "yColumn", z_col = "zColumn",
  new_column_name = "StandardError"
)

# Disconnect from the spark connection
sparklyr::spark_disconnect(sc = sc)
```
